{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-Dataset Normalisation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsmB1RScKFtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader \n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ce_FvKiKhh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size = 5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size = 5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  def forward(self,t):\n",
        "\n",
        "    # (1) Input Layer\n",
        "    t = t\n",
        "\n",
        "    # (2) First Hidden Conv Layer\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # (3) Second Hidden Conv Layer\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # (4) 1st Hidden Linear Layer\n",
        "    t = t.flatten(start_dim = 1)   # t = t.reshape(-1, 12*4*4)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # (5) 2nd Hidden Linear Layer\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # (6) 3rd Hidden Linear Layer\n",
        "    t = self.out(t)\n",
        "\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2MtnZOLKjd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMnist',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "network = Network()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrAL3l4NOIhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunBuilder():\n",
        "\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "\n",
        "    runs = []\n",
        "    for v in product(*params.values()):     # CARTESIAN PRODUCT OF SET ELEMENTS\n",
        "      runs.append(Run(*v))\n",
        "\n",
        "    return runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN3aUlxQQc8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "import time\n",
        "import json"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n2PdRsSKqZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunManager():\n",
        "  def __init__(self):\n",
        "\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    self.run_start_time = None\n",
        "    self.run_data = []\n",
        "    self.run_count = 0\n",
        "    self.run_params = None     # IMPORTANT\n",
        "\n",
        "    self.network = None\n",
        "    self.loader = None\n",
        "    self.tb = None\n",
        "\n",
        "  def begin_run(self, run, network, loader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.loader))\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "\n",
        "\n",
        "      #################      IMPORTANT CHANGE     #####################\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(\n",
        "            self.network\n",
        "        ,images.to(getattr(run, 'device', 'cpu'))            ## CHANGES FOR CPU/GPU are here\n",
        "    )\n",
        "\n",
        "    \n",
        "\n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  def begin_epoch(self):\n",
        "\n",
        "    self.epoch_start_time = time.time()\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "\n",
        "  def end_epoch(self):\n",
        "\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    loss = self.epoch_loss / len(self.loader.dataset)\n",
        "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "    self.tb.add_scalar(\"Loss\", loss, self.epoch_count)\n",
        "    self.tb.add_scalar(\"Accuracy\", accuracy, self.epoch_count)\n",
        "\n",
        "    for name,param in self.network.named_parameters():\n",
        "      self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "\n",
        "    results = OrderedDict()\n",
        "\n",
        "    results['run'] = self.run_count\n",
        "    results['epoch'] = self.epoch_count\n",
        "    results['Loss'] = loss\n",
        "    results['Accuracy'] = accuracy\n",
        "    results['epoch_duration'] = epoch_duration\n",
        "    results['run_duration'] = run_duration\n",
        "\n",
        "    for k,v in self.run_params._asdict().items():\n",
        "      results[k] = v\n",
        "\n",
        "    self.run_data.append(results)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
        "\n",
        "    clear_output(wait = True)\n",
        "    display(df)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def get_number_correct(self, preds, layers):\n",
        "    return preds.argmax(dim = 1).eq(labels).sum().item()\n",
        "\n",
        "  def track_loss(self,loss):\n",
        "    self.epoch_loss += loss.item()*self.loader.batch_size\n",
        "\n",
        "  def track_num_correct(self,preds,labels):\n",
        "    self.epoch_num_correct += self.get_number_correct(preds, labels) \n",
        "\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, orient='columns'\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(self.run_data, f, ensure_ascii=False, indent=4) \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6C8ExYgLZx0",
        "colab_type": "text"
      },
      "source": [
        "# NORMALISING THE DATASET\n",
        "Standardising is a part of Normalisation process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZqteELILjS_",
        "colab_type": "text"
      },
      "source": [
        "## EASY way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoEevuymLZKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
        "data = next(iter(loader))\n",
        "data[0].mean(), data[0].std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv8jF3g8MC1N",
        "colab_type": "text"
      },
      "source": [
        "## HARD way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faJb53FDMFH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DataLoader(train_set, batch_size=1000, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72foTu_zMLti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we calculate our  value or total number of pixels:\n",
        "\n",
        "num_of_pixels = len(train_set) * 28 * 28\n",
        "\n",
        "# (28 * 28) - size of image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Ribc-JML4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating the MEAN\n",
        "\n",
        "total_sum = 0\n",
        "for batch in loader: \n",
        "  total_sum += batch[0].sum() \n",
        "\n",
        "mean = total_sum / num_of_pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2cNp_NsML2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating the STD\n",
        "\n",
        "sum_of_squared_error = 0\n",
        "\n",
        "for batch in loader: \n",
        "    sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()\n",
        "\n",
        "std = torch.sqrt(sum_of_squared_error / num_of_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE5G1gfuNMaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW87b_fyNMQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsWM5gVsMLlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjg5z1pRLJeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set_normal = torchvision.datasets.FashionMNIST(\n",
        "    root='./data/FashionMnist'\n",
        "    ,train=True\n",
        "    ,download=False\n",
        "    ,transform=transforms.Compose([ \n",
        "          transforms.ToTensor()\n",
        "        , transforms.Normalize(mean, std)\n",
        "    ])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpPeRjpfK9DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainsets = {\n",
        "    'not_normal': train_set\n",
        "    ,'normal': train_set_normal\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFcsbXERN8R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product\n",
        "\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "from collections import namedtuple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNw5eqcBLBCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = OrderedDict(\n",
        "      lr = [.01]\n",
        "    , batch_size = [1000]\n",
        "    , num_workers = [1]\n",
        "    , device = ['cuda']\n",
        "    , trainset = ['not_normal', 'normal']\n",
        ")\n",
        "\n",
        "m = RunManager()\n",
        "\n",
        "for run in RunBuilder.get_runs(parameters):\n",
        "\n",
        "  device = torch.device(run.device)             ######## IMPORTANT CHANGE\n",
        "  network = Network().to(device)\n",
        "\n",
        "  loader = DataLoader(train_set, batch_size = run.batch_size)\n",
        "  optimizer = optim.Adam(network.parameters(), lr = run.lr)\n",
        "  \n",
        "  m.begin_run(run, network, loader)\n",
        "\n",
        "  for epoch in range(2):\n",
        "    m.begin_epoch()\n",
        "\n",
        "    for batch in loader:\n",
        "\n",
        "      images  = batch[0].to(device) \n",
        "      labels = batch[1].to(device)\n",
        "\n",
        "      preds = network(images)\n",
        "      loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      m.track_loss(loss)\n",
        "      m.track_num_correct(preds, labels)\n",
        "\n",
        "    m.end_epoch()\n",
        "  m.end_run()\n",
        "\n",
        "m.save('results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifKfZHM-NsRy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLUWXd6INsmQ",
        "colab_type": "text"
      },
      "source": [
        "# Sorting the results according to accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhWvrwbYNqfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame.from_dict(m.run_data).sort_values('Accuracy', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFbUS-VIQHLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPH1OiyeCIzc",
        "colab_type": "text"
      },
      "source": [
        "# Mean and Standard Deviation Calculation for RGB images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRfRq92GCNDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R_channel = 0\n",
        "G_channel = 0\n",
        "B_channel = 0\n",
        "\n",
        "total_pixel = 0\n",
        "for idx in xrange(len(pathDir)):\n",
        "    filename = pathDir[idx]\n",
        "    img = imread(os.path.join(filepath, filename))\n",
        "\n",
        "    total_pixel = total_pixel + img.shape[0] * img.shape[1]\n",
        "\n",
        "    R_total = R_total + np.sum((img[:, :, 0] - R_mean) ** 2)\n",
        "    G_total = G_total + np.sum((img[:, :, 1] - G_mean) ** 2)\n",
        "    B_total = B_total + np.sum((img[:, :, 2] - B_mean) ** 2)\n",
        "\n",
        "R_std = sqrt(R_total / total_count)\n",
        "G_std = sqrt(G_total / total_count)\n",
        "B_std = sqrt(B_total / total_count)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
